\documentclass[12pt]{article}

% Use packages %
\usepackage{graphicx, courier, amsmath, amssymb, amscd, amsfonts, mathtools, bm, esint, leftidx, extarrows, latexsym, relsize, color, tikz, comment, stmaryrd, float}
\usepackage[obeyspaces]{url}% http://ctan.org/pkg/url

% Set length %
\setlength{\textwidth}{160mm}
\setlength{\textheight}{235mm}
\setlength{\oddsidemargin}{-0mm}
\setlength{\topmargin}{-10mm}

% Define h-bar %
\newsavebox{\myhbar}
\savebox{\myhbar}{$\hbar$}
\renewcommand*{\hbar}{\mathalpha{\usebox{\myhbar}}}

% Chinese input %
%\usepackage{xeCJK} 
%\setCJKmainfont{微軟正黑體}
%\usepackage[T1]{fontenc}
%\makeatletter

% Equation number %
%\@addtoreset{equation}{section} 
%\renewcommand\theequation{{\thesection}.{\arabic{equation}}}
%\makeatletter 

% Helper Command %
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\rmnum}[1]{\romannumeral #1} 
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\makeatother
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}
\newcommand*{\QEDB}{\hfill\ensuremath{\square}}
\newcommand*{\BmVert}{\bigm\vert}
\newcommand{\bigslant}[2]{{\raisebox{.2em}{$#1$}\left/\raisebox{-.2em}{$#2$}\right.}}
\newcommand{\Nelements}[3]{\left\{ #1, ~ #2, \ldots, ~ #3 \right\}}
\newcommand{\CBrackets}[1]{\left\{#1\right\}}
\newcommand{\SBrackets}[1]{\left[#1\right]}
\newcommand{\BooBrackets}[1]{\left\llbracket#1\right\rrbracket}
\newcommand{\ParTh}[1]{\left(#1\right)}
\newcommand{\Ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\Floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\BF}[1]{{\bf#1}}
\newcommand{\Inverse}[1]{{#1}^{-1}}
\newcommand{\Generator}[1]{\left\langle#1\right\rangle}
\newcommand{\AbsVal}[1]{\left|#1\right|}
\newcommand{\VecAbsVal}[1]{\left\|#1\right\|}
\newcommand{\BSlash}[2]{\left.#1\middle\backslash#2\right.}
\newcommand{\Divide}[2]{\left.#1\middle/#2\right.}
\newcommand{\SciNum}[2]{#1\times{10}^{#2}}
\newcommand{\Matrix}[2]{\ParTh{\begin{array}{#1}#2\end{array}}}
\newcommand{\MatrixTwo}[4]{\ParTh{\begin{array}{cc}{#1}&{#2}\\{#3}&{#4}\end{array}}}
\newcommand{\MatrixNByN}[1]{\Matrix{cccc}{{#1}_{11} & {#1}_{12} & \cdots & {#1}_{1n} \\ {#1}_{21} & {#1}_{22} & \cdots & {#1}_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ {#1}_{n1} & {#1}_{n2} & \cdots & {#1}_{nn}}}
\newcommand{\ndiv}{\hspace{-4pt}\not|\hspace{2pt}}
\newcommand{\eqdef}{\xlongequal{\text{def}}}%
\newcount\arrowcount
\newcommand\arrows[1]{\global\arrowcount#1 \ifnum\arrowcount>0
\begin{matrix}\expandafter\nextarrow\fi}
\newcommand\nextarrow[1]{\global\advance\arrowcount-1 \ifx\relax#1\relax\else \xrightarrow{#1}\fi\ifnum\arrowcount=0 \end{matrix}\else\\\expandafter\nextarrow\fi}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

% Tikz settings %
\usetikzlibrary{shapes,arrows}
\tikzstyle{decision} = [diamond, draw, fill=white!20, text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block}    = [rectangle, draw, fill=white!20, text width=8em, text centered, rounded corners, minimum height=4em]
\tikzstyle{point}    = [fill = white!20, minimum size=0.5cm]
\tikzstyle{line}     = [draw, -latex']
\tikzstyle{mapsto}   = [draw, |->]
\tikzstyle{cloud}    = [draw, ellipse,fill=red!20, node distance=3cm, minimum height=2em]

\begin{document}

\baselineskip 6.5mm
\setlength{\parindent}{0pt}
\title{ 
\normalfont \normalsize 
\horrule{0.5pt} \\[0.4cm]
\huge { \Huge Machine Learning \\ \large Answer Sheet for Homework 7}\\
\horrule{2pt} \\ [0.5cm]
}
\author{ { \Large Da-Min HUANG } \\
{\small R04942045} \\
{\small\textit{Graduate Institute of Communication Engineering, National Taiwan University}}
}
\date{January 6, 2016}
%\allowdisplaybreaks[4]
\maketitle

\subsection*{Problem 1}

Set $\mu_-=1-\mu_+$, we have
\begin{align}
1-\mu^2_+-\mu^2_-&=1-\mu^2_+-\ParTh{1-\mu_+}^2=\ParTh{1-\mu_+}\ParTh{1+\mu_+}-\ParTh{1-\mu_+}^2\\
&=2\mu_+\ParTh{1-\mu_+}=-2\mu^2_++2\mu_+=-2\ParTh{\mu_+-\dfrac{1}{2}}^2+\dfrac{1}{2}\\
&\leq\dfrac{1}{2}
\end{align}
Hence, if $\mu_+=\Divide{1}{2}\in\SBrackets{0,1}$, then the maximum value of Gini index is $\Divide{1}{2}$.

\QEDB

\horrule{0.5pt}

\subsection*{Problem 2}

The normalized Gini index is
\begin{align}
\dfrac{\ParTh{1-\mu^2_+-\mu^2_-}}{\ParTh{\dfrac{1}{2}}}=2\ParTh{1-\mu^2_+-\mu^2_-}
\end{align}
The squared error can be rewritten as
\begin{align}
\mu_+\ParTh{1-\ParTh{\mu_+-\mu_-}}^2+\mu_-\ParTh{-1-\ParTh{\mu_+-\mu_-}}^2&=4\mu_+\ParTh{1-\mu_+}^2+4\mu^2_+\ParTh{1-\mu_+}\\
&=4\mu_+\ParTh{1-\mu_+}\leq4\times\dfrac{1}{4}=1
\end{align}
Hence the normalized squared error is
\begin{align}
4\mu_+\ParTh{1-\mu_+}&=2\ParTh{2\mu_+\ParTh{1-\mu_+}}=2\ParTh{\ParTh{1-\mu_+}\ParTh{1+\mu_+}-\ParTh{1-\mu_+}^2}\\
&=2\ParTh{1-\mu^2_+-\mu^2_-}
\end{align}
which is equal to normalized Gini index.

\QEDB

\horrule{0.5pt}

\subsection*{Problem 3}

The probability of one example not sampled is
\begin{align}
\ParTh{1-\dfrac{1}{N}}^{pN}=\dfrac{1}{\ParTh{\dfrac{N}{N-1}}^{pN}}=\dfrac{1}{\ParTh{1+\dfrac{1}{N-1}}^{pN}}=\ParTh{\dfrac{1}{\ParTh{1+\dfrac{1}{N-1}}^{N}}}^p
\end{align}
As $N\rightarrow\infty$, we have
\begin{align}
\lim\limits_{N\rightarrow\infty}\ParTh{\dfrac{1}{\ParTh{1+\dfrac{1}{N-1}}^{N}}}^p=\ParTh{\lim\limits_{N\rightarrow\infty}\dfrac{1}{\ParTh{1+\dfrac{1}{N-1}}^{N}}}^p=\ParTh{\dfrac{1}{e}}^p=e^{-p}
\end{align}
So there approximately $e^{-p}\cdot N$ of the examples not sampled.

\QEDB

\horrule{0.5pt}

\subsection*{Problem 4}

Since $G=\text{Uniform}\ParTh{\CBrackets{g_k}^3_{k=1}}$, so if at least two terms of $\CBrackets{g_k}^3_{k=1}$ ouput wrong result, then $G$ outputs wrong result. Let $\CBrackets{E_k}^3_{k=1}$ be the set of examples that $\CBrackets{g_k}^K_{k=1}$ got wrong results. Apparently $\AbsVal{E_3}>\AbsVal{E_2}>\AbsVal{E_1}$ and $\AbsVal{E_1}+\AbsVal{E_2}>\AbsVal{E_3}$. So
\begin{enumerate}
	\item Maximum of $E_{\text{out}}\ParTh{G}$ happens at $E_3\subset\ParTh{E_1\cup E_2}$. Then $G$ outputs wrong result in the region of $E_3$ with $E_{\text{out}}\ParTh{G}=0.35$.
	\item Minimum of $E_{\text{out}}\ParTh{G}$ happens at $E_i\cap E_j=\phi$, $i\neq j$ and $1\leq i,j\leq 3$ with $i,j\in\mathbb{N}$. Then $G$ always ouputs the correct result since $\ParTh{E_1\cup E_2\cup E_3}\subset\CBrackets{\text{all examples}}$.
\end{enumerate}
Hence, $0\leq E_{\text{out}}\ParTh{G}\leq0.35$.
\begin{comment}
\begin{align}
\nonumber
&~0.15\times0.25\times0.65+0.25\times0.35\times0.85+0.15\times0.35\times0.75+0.15\times0.25\times0.35\\
=&~0.15125
\end{align}
\end{comment}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 5}

Since $G=\text{Uniform}\ParTh{\CBrackets{g_k}^K_{k=1}}$, so if at least $\Divide{\ParTh{K+1}}{2}$ terms of $\CBrackets{g_k}^K_{k=1}$ ouput wrong result, then $G$ outputs wrong result. Let $\CBrackets{E_k}^K_{k=1}$ be the set of examples that $\CBrackets{g_k}^K_{k=1}$ got wrong results.

If $G$ outputs wrong result on some example $\BF{x}$, then we have
\begin{align}
\BF{x}\in\bigcap^{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}_{i=1}E_{\alpha_i}
\end{align}
where $\alpha_i$ is some index satisfies $1\leq\alpha_i\leq K$ and $m\in\ParTh{\mathbb{N}\cup\CBrackets{0}}$ with $0\leq m<\Divide{\ParTh{K+1}}{2}$. And
\begin{align}
\AbsVal{\bigcap^{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}_{i=1}E_{\alpha_i}}\leq\dfrac{2}{K+1+2m}\sum_{k=1}^{K}e_k\leq\dfrac{2}{K+1}\sum_{k=1}^{K}e_k
\label{5-1}
\end{align}
(\ref{5-1}) holds due to %$\AbsVal{\bigcap^{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}_{i=1}E_{\alpha_i}}\leq\frac{2}{K+1+2m}\sum_{k=1}^{K}e_k$ holds due to
\begin{align}
\bigcap^{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}_{i=1}E_{\alpha_i}\subseteq E_{\beta}
\end{align}
where $\beta$ is some index such that $\AbsVal{E_{\beta}}=\min_{\alpha_i}\AbsVal{E_{\alpha_i}}$. So
\begin{align}
\ParTh{\dfrac{K+1}{2}+m}\AbsVal{\bigcap^{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}_{i=1}E_{\alpha_i}}\leq\ParTh{\dfrac{K+1}{2}+m}\AbsVal{E_{\beta}}\leq\sum_{k=1}^{K}\AbsVal{E_k}
\label{5-2}
\end{align}
(\ref{5-2}) holds since size of $E_\beta$ is the samllest among $\ParTh{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}$ terms and $\sum_{k=1}^{K}\AbsVal{E_k}$ must contains the $\ParTh{\ParTh{\Divide{\ParTh{K+1}}{2}}+m}$ terms.

Hence, we have
\begin{align}
E_{\text{out}}\ParTh{G}\leq\dfrac{2}{K+1}\sum_{k=1}^{K}e_k
\end{align}
\begin{comment}
\begin{align}
\dfrac{2}{M+1}\sum_{k=1}^{M}e_k\leq\dfrac{2}{M+3}\sum_{k=1}^{M+2}e_k=\dfrac{2}{M+3}\ParTh{\sum_{k=1}^{M}e_k+e_{M+1}+e_{M+2}}
\end{align}
\begin{align}
\dfrac{4}{\ParTh{M+1}\ParTh{M+3}}\sum_{k=1}^{M}e_k-e_{M+1}-e_{M+2}
\end{align}
\end{comment}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 6}

By the definition of $U_{t}$, we have
\begin{align}
U_{t+1}&=\dfrac{1}{N}\sum_{n=1}^{N}\exp\ParTh{-y_n\sum_{\tau=1}^{t}\alpha_\tau g_\tau\ParTh{\BF{x}_n}}\\
&=\dfrac{1}{N}\sum_{n=1}^{N}\exp\ParTh{-y_n\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\ParTh{\BF{x}_n}-y_n\alpha_tg_t\ParTh{\BF{x}_n}}\\
&=\dfrac{1}{N}\sum_{n=1}^{N}\exp\ParTh{-y_n\sum_{\tau=1}^{t-1}\alpha_\tau g_\tau\ParTh{\BF{x}_n}}\exp\ParTh{-y_n\alpha_tg_t\ParTh{\BF{x}_n}}\\%=U_{t}\exp\ParTh{\alpha_tg_t\ParTh{\BF{x}_n}}\\
&=\sum_{n=1}^{N}u^{\ParTh{t}}_n\exp\ParTh{-y_n\alpha_tg_t\ParTh{\BF{x}_n}}\\
&=\sum_{\substack{n \\ y_n\neq g_t\ParTh{\BF{x}_n}}}u^{\ParTh{t}}_n\exp\ParTh{-y_n\alpha_tg_t\ParTh{\BF{x}_n}}+\sum_{\substack{n \\ y_n=g_t\ParTh{\BF{x}_n}}}u^{\ParTh{t}}_n\exp\ParTh{-y_n\alpha_tg_t\ParTh{\BF{x}_n}}\\
&=\sum_{\substack{n \\ y_n\neq g_t\ParTh{\BF{x}_n}}}u^{\ParTh{t}}_n\exp\ParTh{\alpha_t}+\sum_{\substack{n \\ y_n=g_t\ParTh{\BF{x}_n}}}u^{\ParTh{t}}_n\exp\ParTh{-\alpha_t}\\
&=\exp\ParTh{\alpha_t}\ParTh{\epsilon_t}\sum_{n=1}^{N}u^{\ParTh{t}}_n+\exp\ParTh{-\alpha_t}\ParTh{1-\epsilon_t}\sum_{n=1}^{N}u^{\ParTh{t}}_n\\
&=U_t\ParTh{\exp\ParTh{\alpha_t}\ParTh{\epsilon_t}+\exp\ParTh{-\alpha_t}\ParTh{1-\epsilon_t}}=U_t\cdot2\sqrt{\epsilon_t\ParTh{1-\epsilon_t}}
\end{align}
Since
\begin{align}
U_{1}=\sum_{n=1}^{N}u^{\ParTh{1}}_n=\sum_{n=1}^{N}\dfrac{1}{N}=1
\end{align}
we have
\begin{align}
U_3&=U_2\cdot2\sqrt{\epsilon_2\ParTh{1-\epsilon_2}}=\ParTh{U_1\cdot2\sqrt{\epsilon_1\ParTh{1-\epsilon_1}}}\cdot2\sqrt{\epsilon_2\ParTh{1-\epsilon_2}}\\
&=4\sqrt{\epsilon_1\epsilon_2\ParTh{1-\epsilon_1}\ParTh{1-\epsilon_2}}
\end{align}
which can be generalized as
\begin{align}
U_{T+1}=\prod_{t=1}^{T}\ParTh{2\sqrt{\epsilon_t\ParTh{1-\epsilon_t}}}
\end{align}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 7}

To compute $s_n$, we need to find the optimal $\eta$ of
\begin{align}
\min_\eta\dfrac{1}{N}\sum_{n=1}^{N}\ParTh{\ParTh{y_n-s_n}-\eta g_t\ParTh{\BF{x}_n}}^2\coloneqq A
\end{align}
From $\Divide{\partial A}{\partial\eta}=0$, we have
\begin{align}
\eta=\dfrac{\sum_{n=1}^{N}g_t\ParTh{\BF{x}_n}\ParTh{y_n-s_n}}{\sum_{n=1}^{N}g^2_t\ParTh{\BF{x}_n}}
\end{align}
Now $s_n=0$ and $g_1\ParTh{\BF{x}}=2$, so
\begin{align}
\eta=\dfrac{2\sum_{n=1}^{N}y_n}{4\sum_{n=1}^{N}}=\dfrac{1}{2N}\sum_{n=1}^{N}y_n
\end{align}
Since $\eta=\alpha_1$, so
\begin{align}
\alpha_1g_1\ParTh{\BF{x}_n}=\dfrac{2}{2N}\sum_{n=1}^{N}y_n=\dfrac{1}{N}\sum_{n=1}^{N}y_n=s_n
\end{align}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 8}

From the equatio of optimal $\eta$, we have
\begin{align}
\eta=\dfrac{\sum_{n=1}^{N}g_t\ParTh{\BF{x}_n}\ParTh{y_n-s^\prime_n}}{\sum_{n=1}^{N}g^2_t\ParTh{\BF{x}_n}}=\dfrac{\sum_{n=1}^{N}y_ng_t\ParTh{\BF{x}_n}-\sum_{n=1}^{N}s^\prime_ng_t\ParTh{\BF{x}_n}}{\sum_{n=1}^{N}g^2_t\ParTh{\BF{x}_n}}=\alpha_t
\end{align}
so
\begin{align}
\sum_{n=1}^{N}y_ng_t\ParTh{\BF{x}_n}-\sum_{n=1}^{N}s^\prime_ng_t\ParTh{\BF{x}_n}=\alpha_t\sum_{n=1}^{N}g^2_t\ParTh{\BF{x}_n}=\sum_{n=1}^{N}\alpha_tg^2_t\ParTh{\BF{x}_n}=\sum_{n=1}^{N}\ParTh{s_n-s^\prime_n}g_t\ParTh{\BF{x}_n}
\end{align}
where $s^\prime_n$ is defined as the $s_n$ in iteration $\ParTh{t-1}$ and $s_n=s^\prime_n+\alpha_tg_t\ParTh{\BF{x}_n}$, so
\begin{align}
\sum_{n=1}^{N}s_ng_t\ParTh{\BF{x}_n}=\sum_{n=1}^{N}y_ng_t\ParTh{\BF{x}_n}
\end{align}
%Since all $s_n$ are updated in iteration $t$, we have

\QEDB

\horrule{0.5pt}

\subsection*{Problem 9}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 10}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 11}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 12}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 13}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 14}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 15}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 16}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 17}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 18}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 19}

\QEDB

\horrule{0.5pt}

\subsection*{Problem 20}

\QEDB

\horrule{0.5pt}

\section*{Reference}

\begin{enumerate}

\item[{[1]}] Lecture Notes by Hsuan-Tien LIN, Department of Computer Science and Information Engineering, National Taiwan University, Taipei 106, Taiwan.

\end{enumerate}

\end{document}